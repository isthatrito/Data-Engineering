{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the Spark Context\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset as a list\n",
    "data = [('patty', 'spring', 'baseball', 64),\n",
    "        ('patty', 'autumn', 'soccer', 78),\n",
    "        ('matty', 'autumn', 'hockey', 90),\n",
    "        ('matty', 'spring', 'soccer', 64),\n",
    "        ('cathy', 'spring', 'baseball', 100),\n",
    "        ('cathy', 'autumn', 'hockey', 78),\n",
    "        ('sandy', 'autumn', 'soccer', 50),\n",
    "        ('joey', 'summer', 'soccer', 73),\n",
    "        ('tammy', 'spring', 'soccer', 86),\n",
    "        ('marley', 'autumn', 'hockey', 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an rdd\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:194"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from an rdd and name the columns\n",
    "df = spark.createDataFrame(rdd, ['player', 'season', 'sport', 'ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+\n",
      "|player|season|   sport|ranking|\n",
      "+------+------+--------+-------+\n",
      "| patty|spring|baseball|     64|\n",
      "| patty|autumn|  soccer|     78|\n",
      "| matty|autumn|  hockey|     90|\n",
      "| matty|spring|  soccer|     64|\n",
      "| cathy|spring|baseball|    100|\n",
      "| cathy|autumn|  hockey|     78|\n",
      "| sandy|autumn|  soccer|     50|\n",
      "|  joey|summer|  soccer|     73|\n",
      "| tammy|spring|  soccer|     86|\n",
      "|marley|autumn|  hockey|    100|\n",
      "+------+------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another dataset called meta\n",
    "meta = [('patty', 'community', 25),\n",
    "        ('matty', 'college', 35),\n",
    "        ('cathy', 'community', 40),\n",
    "        ('sandy', 'college', 60),\n",
    "        ('joey', 'community', 55),\n",
    "        ('tammy', 'college', 23),\n",
    "        ('marley', 'community', 45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create schema\n",
    "schema = StructType([\n",
    "    StructField('player', StringType(), True),\n",
    "    StructField('league', StringType(), True),\n",
    "    StructField('age', IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe, using dataset and schema\n",
    "df_meta = spark.createDataFrame(meta, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+\n",
      "|player|   league|age|\n",
      "+------+---------+---+\n",
      "| patty|community| 25|\n",
      "| matty|  college| 35|\n",
      "| cathy|community| 40|\n",
      "| sandy|  college| 60|\n",
      "|  joey|community| 55|\n",
      "| tammy|  college| 23|\n",
      "|marley|community| 45|\n",
      "+------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show dataframe\n",
    "df_meta.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+---------+---+\n",
      "|player|season|   sport|ranking|   league|age|\n",
      "+------+------+--------+-------+---------+---+\n",
      "|marley|autumn|  hockey|    100|community| 45|\n",
      "| sandy|autumn|  soccer|     50|  college| 60|\n",
      "|  joey|summer|  soccer|     73|community| 55|\n",
      "| tammy|spring|  soccer|     86|  college| 23|\n",
      "| cathy|spring|baseball|    100|community| 40|\n",
      "| cathy|autumn|  hockey|     78|community| 40|\n",
      "| matty|autumn|  hockey|     90|  college| 35|\n",
      "| matty|spring|  soccer|     64|  college| 35|\n",
      "| patty|spring|baseball|     64|community| 25|\n",
      "| patty|autumn|  soccer|     78|community| 25|\n",
      "+------+------+--------+-------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# right outer join\n",
    "df_full = df.join(df_meta, on='player', how='rightouter')\n",
    "df_full.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view table to use SQL\n",
    "df_full.createOrReplaceTempView('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|player|age|\n",
      "+------+---+\n",
      "|marley| 45|\n",
      "| sandy| 60|\n",
      "|  joey| 55|\n",
      "| tammy| 23|\n",
      "| cathy| 40|\n",
      "| cathy| 40|\n",
      "| matty| 35|\n",
      "| matty| 35|\n",
      "| patty| 25|\n",
      "| patty| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns\n",
    "spark.sql('select player, age from table').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|player|age|\n",
      "+------+---+\n",
      "|marley| 45|\n",
      "| sandy| 60|\n",
      "|  joey| 55|\n",
      "| cathy| 40|\n",
      "| matty| 35|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows\n",
    "spark.sql('select player, age from table where age > 25').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|player|adj_age|\n",
      "+------+-------+\n",
      "|marley|     50|\n",
      "| sandy|     65|\n",
      "|  joey|     60|\n",
      "| tammy|     28|\n",
      "| cathy|     45|\n",
      "| cathy|     45|\n",
      "| matty|     40|\n",
      "| matty|     40|\n",
      "| patty|     30|\n",
      "| patty|     30|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mutate table\n",
    "spark.sql('select player, age + 5 as adj_age from table').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|player|age|\n",
      "+------+---+\n",
      "| sandy| 60|\n",
      "|  joey| 55|\n",
      "|marley| 45|\n",
      "| cathy| 40|\n",
      "| matty| 35|\n",
      "| patty| 25|\n",
      "| tammy| 23|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns\n",
    "spark.sql('select player, age from table order by age desc').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|    38.3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean\n",
    "spark.sql('select mean(age) from table').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-apply-combine\n",
    "q = '''\n",
    "select league, mean(ranking), max(age)\n",
    "from table\n",
    "group by league\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+--------+\n",
      "|   league|     avg(ranking)|max(age)|\n",
      "+---------+-----------------+--------+\n",
      "|  college|             72.5|      60|\n",
      "|community|82.16666666666667|      55|\n",
      "+---------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display result\n",
    "spark.sql(q).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pyspark.sql.functions as built in functions\n",
    "\n",
    "ranking_players = (\n",
    "    F.\n",
    "    when(F.col('ranking') > 90, 'Top Ten').\n",
    "    when(F.col('ranking') > 80, 'Top Twenty').\n",
    "    otherwise('average player')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+---------------+\n",
      "|player|season|   sport|ranking|player_standing|\n",
      "+------+------+--------+-------+---------------+\n",
      "| patty|spring|baseball|     64| average player|\n",
      "| patty|autumn|  soccer|     78| average player|\n",
      "| matty|autumn|  hockey|     90|     Top Twenty|\n",
      "| matty|spring|  soccer|     64| average player|\n",
      "| cathy|spring|baseball|    100|        Top Ten|\n",
      "| cathy|autumn|  hockey|     78| average player|\n",
      "| sandy|autumn|  soccer|     50| average player|\n",
      "|  joey|summer|  soccer|     73| average player|\n",
      "| tammy|spring|  soccer|     86|     Top Twenty|\n",
      "|marley|autumn|  hockey|    100|        Top Ten|\n",
      "+------+------+--------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create another column in the dataframe\n",
    "df.withColumn('player_standing', ranking_players).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use write mode to overwrite file as a csv file\n",
    "df_full.write.mode('overwrite').option('header', 'true').csv('listplayers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read option to read csv file\n",
    "df1 = spark.read.option('header', 'true').csv('listplayers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+---------+---+\n",
      "|player|season|   sport|ranking|   league|age|\n",
      "+------+------+--------+-------+---------+---+\n",
      "| cathy|spring|baseball|    100|community| 40|\n",
      "| cathy|autumn|  hockey|     78|community| 40|\n",
      "| patty|spring|baseball|     64|community| 25|\n",
      "| patty|autumn|  soccer|     78|community| 25|\n",
      "| matty|autumn|  hockey|     90|  college| 35|\n",
      "| matty|spring|  soccer|     64|  college| 35|\n",
      "|marley|autumn|  hockey|    100|community| 45|\n",
      "|  joey|summer|  soccer|     73|community| 55|\n",
      "| tammy|spring|  soccer|     86|  college| 23|\n",
      "| sandy|autumn|  soccer|     50|  college| 60|\n",
      "+------+------+--------+-------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use write mode to overwrite as json file\n",
    "df_full.write.mode('overwrite').json('listplayers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read json to read file\n",
    "df2 = spark.read.json('listplayers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+-------+------+--------+\n",
      "|age|   league|player|ranking|season|   sport|\n",
      "+---+---------+------+-------+------+--------+\n",
      "| 40|community| cathy|    100|spring|baseball|\n",
      "| 40|community| cathy|     78|autumn|  hockey|\n",
      "| 25|community| patty|     64|spring|baseball|\n",
      "| 25|community| patty|     78|autumn|  soccer|\n",
      "| 35|  college| matty|     90|autumn|  hockey|\n",
      "| 35|  college| matty|     64|spring|  soccer|\n",
      "| 45|community|marley|    100|autumn|  hockey|\n",
      "| 55|community|  joey|     73|summer|  soccer|\n",
      "| 23|  college| tammy|     86|spring|  soccer|\n",
      "| 60|  college| sandy|     50|autumn|  soccer|\n",
      "+---+---------+------+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use write mode to overwrite as parquet file\n",
    "df_full.write.mode('overwrite').parquet('listplayers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use read parquet to read file\n",
    "df3 = spark.read.parquet('listplayers.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+---------+---+\n",
      "|player|season|   sport|ranking|   league|age|\n",
      "+------+------+--------+-------+---------+---+\n",
      "| patty|spring|baseball|     64|community| 25|\n",
      "| patty|autumn|  soccer|     78|community| 25|\n",
      "| cathy|spring|baseball|    100|community| 40|\n",
      "| cathy|autumn|  hockey|     78|community| 40|\n",
      "| matty|autumn|  hockey|     90|  college| 35|\n",
      "| matty|spring|  soccer|     64|  college| 35|\n",
      "|marley|autumn|  hockey|    100|community| 45|\n",
      "|  joey|summer|  soccer|     73|community| 55|\n",
      "| sandy|autumn|  soccer|     50|  college| 60|\n",
      "| tammy|spring|  soccer|     86|  college| 23|\n",
      "+------+------+--------+-------+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display result\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
